---
layout: post
title:  Modello di Rilevanza Statistica di Salmon
date:   2021-10-05 12:40:16
tags: filosofia
description: Teoria della spiegazione scientifica secondo Salmon.

---

The goal is to overcome the Hempelian models, i.e. the deterministic approach to scientific explanation (Hempel). Nevertheless, it is true that we cannot exclude deterministic phenomena. We need a concept that does not exclude these two visions, and to achieve this it is necessary to introduce the concept of **statistical significance**, related to the fact that $$P(B\vert A) \neq P(B)$$. Statistical significance is the property of an event to change the probability of another event. What accounts for the occurrence of an event are all those events that change the probability of occurrence of that event, i.e., all events $$A$$ that are relevant with respect to $$B$$ according to the definition given above. When we ask about the nature of event $$B$$ we must take into account all such events $$A$$. Hempel's models do not allow us to select relevant events from those that are not. On the other hand, in the **Statistical Relevance (SR)** model explanatory relevance is statistical relevance, i.e., what explains an event $$B$$ are all and only the events $$A$$ that are statistically relevant with respect to $$B$$. How do I measure this statistical significance? By calculating the frequencies. For example, if $$P(B\vert C) = P(B)$$, the event $$C$$ is not relevant with respect to $$B$$ and we do not have to take it into account when explaining $$B$$.

Salmon formulated his theory of scientific explanation in Statistical Explanation in the early 1970s. He formulates the statistical significance model with the intent of overcoming Hempelian models. Salmon's intent is to overcome the Hempelian relativization that statistical explanation depends on cognitive context.

One of the big theoretical problems is that at least some phenomena behave in an inherently probabilistic way. Assuming that a certain set of phenomena do, are there areas in which probability also represents degrees of ignorance? Can I find a model that includes both forms of probability, the intrinsic one and the one that emerges from ignorance of the phenomena?

Salmon formulates an indeterministic model in which the key concept is that of pure statistical relevance. A certain proposition $$A$$ is relevant with respect to $$B$$ if $$P(B\vert A) \neq P(B)$$. Pure wording means that we don't care about lesser or greater, but we do care that there is a difference relationship. While in median models what explains are laws, here the explanatory relevance is statistical relevance: what explains are statistically relevant events, i.e., what changes the probability of a given event to occur.

When I explain something there is something I know and something I want to find out. Therefore it is natural to start with a reference class $$A$$ to which an event $$x$$ belongs and I want to explain why the event $$B$$ has the property $$x$$. When I deal with something I know something about the reference class $$A$$. Let's start with an example: the event $$B$$ is the theft of a car and $$A$$ is the class of American kids. There is a certain probability of stealing a car if I am an American boy, $$P(B\vert A) = p_1$$. Salmon's method proceeds as follows: I look for those properties that give some difference with what I know, namely $$P(B\vert A \dots) \neq P(B\vert A)$$. Among the American $$A$$ boys there are those with the property $$C$$ of having a criminal record: if $$P(B\vert A \cdot C) \neq P(B\vert A)$$, i.e. the probability is different from just being an American boy, I will have to take into account $$C$$ as a statistical relevant [^1]

In this process explaining means taking the class $$A$$ and dividing it into subclasses. How? According to statistically relevant properties. I perform partitions of $$A$$ across all statistically relevant properties.  When do I get to the explanation? When I have performed the full partition of all statistically relevant properties and only those, emphasizing all and only those (this is a fairly strong and stringent statement). Then in this model explaining means attributing my individual to the reference class to which he belongs. The fact that he belongs to that class is the explanation of why he stole a car. 

The main idea is that explaining *isn't logical reasoning* but rather a **succession of partitions of my reference class** (which is what I already know, my starting point). The partition must shape the set of mutually exclusive and exhaustive subclasses. Each element of the initial class belongs to one and only one of the classes. Eventually there will be only one cell where the actual reference subject can belong. It is not important that the probability of the explanandum is high or low what matters is that the information is relevant to its occurrence. Statistical relevance guides the choice of the appropriate reference class. This is because we want to include also in our model indeterministic phenomena.

A first difference with the previous models is for example with the I-S model, in which a very high probability is required, while for the Salmon model it is necessary to be relevant, no matter how much. [^2]

Fundamental criterion for a good explanation is the homogeneity of the reference class: a good explanation includes all and only the relevant information with respect to the event to be explained, and until I have finished the restart I cannot say in which cell to put Albert. Including only relevant information solves several problems (such as that of explaining events that are unlikely to occur). Homogeneity of the reference class is achieved through successive partitions of the reference cells by relevant attribbits. A class that is homogeneous with respect to a given attribute is a class that cannot be further partitioned by means of statistically relevant attribbits with respect to the property being explained.

This model was created to overcome the limitations of Hempelian models and it is intended to be compatible with an indeterministic approach, but also open to deterministic models. In Hempel the preferred explanations are the deterministic ones while the statistical ones are the imperfect cases of the deductive explanations; for Salmon it is the _contrary_, the deductive explanations are limit cases of the statistical explanations. For the latter, the probabilistic explanation constitutes the general case: the deterministic explanation represents the special case in which the statistically relevant partition gives rise to only two cells: one in which the attribute of the explanandum appears the associated porbability and one, the other empty.

The Hempelian model was intended to be universal and valid for any scientific discipline. Even the S-R models of the 1970s-80s were to be used in all sciences according to Salmon. However, many criticisms have been made of Salmon on the type of examples he chooses to give to explain his models. For example, is it easy to be certain at a certain time $t_0$ that he has taken all statistically relevant properties or does this depend on external factors (progress, historical context etc.)? Homogeneity as a criterion has been accused of being too strong a requirement for the humanities and social sciences, whereas it is clearly easier to use in certain more exact disciplines.

To overcome this criticism Salmon introduces a further concept: the **objectively homogeneous reference class**. This is defined as the reference class which in principle cannot be broken down into further subclasses independently of our knowledge. Right after this definition, however, Salmon states that objective homogeneity is an _ideal_. Always remember that Salmon's goal is to admit the possibility of genuine statistical explanations that are not relative to epistemic context. In contrast to an objectively homogeneous reference class there is the epistically homogeneous reference class: a homogeneous reference class is epistemic if the available knowledge does not allow for partitioning. Salmon admits the existence of epistemic explanations because there are properties yet to be discovered that nevertheless confirm to me the statistical nature of the explanation (as opposed to Hempel for whom increasing knowledge actually decreased statistical influence). There are also the pragmatically homogeneous classes: I could share them again but for practical reasons I decide not to.

The **explanation**, according to Salmon, is to attribute the reference cell to Albert, our American boy. The explanation is a kind of assemblage of all statistically relevant factors regardless of their probability value. The goodness of an explanation is the gain in information provided by the complete partitions and associated probabilities. PLEASE NOTE: This is not a **causal** model since I have identified characteristics of the individual related to exhibiting a certain property, but I have not found any cause-and-effect linkages through this procedure. The S-R model is a **nomological** model since the statements expressing the assignments of the initial and final probability values are treated as statistical laws[^3] 

In addition the S-R explanation is not **inferential**: it wants to overcome the Hempelian explanations but it remains nomological because the explanations remain statistical in nature, in fact like the Hempelian statistical laws. In fact, to say that the probability of stealing a car by someone living in a certain neighborhood is a law or a statistical accidental generalization? To say that there is a link between living in a certain neighborhood and being a thief based on statistical correlations is a bit strong and certainly not a law. Is **explanatory relevance** exhausted by being statistically significant? The obvious answer is no, because there are statistically relevant properties that are not explanatory. From this extremely critical point Salmon will develop a new model, with a second level of explanation that will allow one to arrive at the causal explanation.

Another problem that emerges from Hempelian models is a question of a more general nature: **do laws explain or describe?** Once I have the law, such as all heated metals conduct heat, it comes instinctive to ask: why does this happen? _The formulation of a law seems to prompt us to ask for an explanation of what the law asserts rather than describe it_. Therefore it is concluded that the law itself is not an explanatory but a descriptive operation. We could say that the demonstration of the law (if we can talk about it, it depends on the context) explains the law, while the statement only describes it. Not that the description is not important from the scientific point of view, but to describe something is not to explain it. A further criticism that can be made of Salmon is: if I accuse Hempel of providing models that aspire to be explanatory but are only descriptive and then build a nomological model in which the problem of describing the law remains, given the statistical nature of the model, then do I not preserve the problems of the Hempelian models?

### Summary

<ul>
<li> Strengths(compared to Hempelian models) </li>
  <ul>
    <li> SR is non-inferential and therefore does not fall into the problems of hempelian models </li>
    <li> It also admits the explanation of unlikely events.  </li>
    <li> I assume that there is an availability of statistical generalizations, which however is not thematized (how the generalizations are derived is not taken up in the discussion of the model), that allow me to efficiently partition my reference class. </li>
    <li> Tends toward objective homogenization </li>
    <li> Breaks the symmetry between explanation and prediction in the sense of nomic reliability: an explanation does not necessarily indicate that the event in question should be expected. Reliability is rejected entirely. Given all the relevant information we can establish what expectations are reasonable to have about the event, not connecting cause and effect, however. The explanation remains of statistical-probabilistic nature. </li>
    <li> We do not obtain one reliability nomica but we have the possibility to attribute the correct probability to associate to a sure event. Therefore predictive property of the model are of probabilistic nature not of cause effect. </li>
    <li> I assume that there is an availability of statistical generalizations which however is not thematized (how the generalizations are derived is not taken care of in the discussion of the model), that allow me to efficiently partition my reference class. </li>  
  </ul>
<li> Limitations of the SR model </li>
  <ul>
    <li> Do nomic utterances explain or describe? </li>
    <li> Possible to equate explanatory relevance with statistical relevance?  </li>
  </ul>
</ul>

Salmon does not disavow this model at all, but rather it becomes the first level of another model developed in the 1980s. The SR model then goes from being a stand-alone model to being the first stage of a larger model. This first phase is necessary to throw out anything that is not explanatory; it is a kind of preliminary work of cleaning up the field. Once I have all the statistically relevant properties I will have to go and find the **casually relevant** ones: I will have to identify which statistical correlations are detected from the frequency point of view because there is an underlying causal link. The SR explanation is not eliminated but it becomes a preliminary tool to eliminate irrelevant information, it becomes a kind of filter. We move from the idea that explanatory relevance is statistical relevance to the fact that explanatory relevance is causal relevance. If I just stop at the statistical level, I don't come out if my intent is explanatory.[^4]


To understand how Salmon's model will proceed let's take an example of a symptomatic explanation: if $$B$$ is the abrupt displacement of the barometer hand and $$T$$ is the time event, then $$P(T\vert B) > P(T)$$. But it is certainly not the moving hand that explains the thunderstorm. Let $$A$$ be the lowering of the atmospheric pressure. It is necessary to introduce the rule of adumbration (screening off): this asserts that relevant propositions become irrelevant in light of other properties, i.e. in the case where $$P(T\vert A \cdot B) = P(T\vert A)$$, i.e. $$B$$ is irrelevant with respect to $$T$$ if I also have $$A$$. We then say that $$A$$ **shadows** the statistical dependence of $$B$$ with respect to $$T$$. The reverse is not true, $$P(T\vert A \cdot B) \neq P(T\vert B)$$ (if I have a broken barometer, for example). Adumbration signals an asymmetry between the properties/events $$A$$ and $$B$$. $$A$$ and $$B$$ have different characteristics, they do not have the same role and weight. The adumbration rule then tells us that _no adumbrate property can be included in an S-R_ explanation. If $$A$$ adumbrates $$B$$ then $$B$$ has no explanatory relevance (it has statistical relevance but not explanatory relevance). Instead, the explanation must include the property that operates the adumbration. However, we have the usual problem discussed earlier: can I have definite explanations if in principle there may be properties momentarily unknown to me that adumbrate explanatorily relevant properties now? We will see that this adumbration rule will not be sufficient.

[^1]: But what if statistically relevant properties are contradictory? 
[^2]: But the many cells I partition my $$A$$ into, how can I be sure they are mutually exclusive? There is no single way to partition. 
[^3]: Bibliographic reference: Forty years of scientific explanation, by Salmon; it is not neutral as a book, since he tries to bring water to his mill)
[^4]: The whole part about big data is a big topic in this regard. Bibliographic References: Sabina Leonelli -> philosophy of science on data driven science on theoretical issues of BIG DATA (Nov 23) -> STS approach, philosophy of science with aspects more related to sociology and history.


